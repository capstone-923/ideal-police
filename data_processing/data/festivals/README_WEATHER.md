# Scripts & Processed Festival Data

This repository contains scripts for downloading, processing, and analyzing Toronto's general festival data of both 2014-2016 and 2017 January-2019 September. Most of data files can be found in the [Google Drive folder](https://drive.google.com/drive/folders/1esWev9RbiMcrsVrJNU8vd6m4UDqvDcze).

---

## Folder Overview

### **1. `festival_data`**

#### **`url_download.py`**:
- The python script creates a resources_metadata.json that stores all three types of dataset contained in Toronto Open Data Portal for festival datasets. 
  - **festivals-and-events-historical-xml-feed-jan-2014-dec-2016**
  - **festivals-and-events-readme**
  - **Festivals and events json feed**
- The `festivals-and-events-readme` is a README file for the categories' abbreviation in the `festivals-and-events-historical-xml-feed-jan-2014-dec-2016` and `Festivals and events json feed`
- The `festivals-and-events-historical-xml-feed-jan-2014-dec-2016` dataset contain all festival events from 2014 to 2016 in xml format.
-The `Festivals and events json feed` contain all registered festival events from today into future in json format. 

#### **`2014_2016_cleaning.py`**:
- This python file converts `festivals-and-events-historical-xml-feed-jan-2014-dec-2016`'s XML format into CSV format useable for this project.
- The CSV file generated by this program will be feed into `2014_2016_process.py` for more detailed filtering. 
- The files are not combined for debugging purposes. 
- Requires installation of `pandas`
  - In Command Window, install pandas module using the command `pip install pandas`

#### **`2014_2016_process.py`**:
- This python file processed the CSV file extracted using `2014_2016_cleaning.py` and output a CSV dataset useable for extracting numbers of the categorical data. 

  > **_Note_**: Dataset Details for 2014-2016 CSV specifically
  > - **Date Range**: 2014-01-01 to 2016-12-31  
  > - **Original Datasets**: Access the cleaned dataset in [festival_events_new](https://drive.google.com/drive/folders/1gMpm_jdO8CvqzOAeAdXA091jbS1Rt8dc?usp=drive_link), under the name of `final_cleaned_2014_2016.zip`



- **Merged Data**:
  - `merged_data.csv`: Consolidated raw data.
- **Cleaned Data**:
  - `basic_clean_data.csv`: Simplified dataset with unnecessary columns removed.
  - `basic_clean_data_report.csv`: Data quality analysis (Non-Blank Cell Rate) for `basic_clean_data.csv`.
  - `deep_clean_data.csv`: Data with selected features in a structured format.
  - `filled_deep_clean_data.csv`: Data with missing values filled via interpolation.

#### **processed_data.zip**
[processed_data.zip](https://drive.google.com/file/d/1iDcF_ue2426kqFgCm7rr8Y8puqZFQ7q0/view?usp=drive_link).
- **`TORONTO_CITY_processed_data.csv`**
- **`TORONTO_CITY_CENTRE_processed_data.csv`**
- **`TORONTO_INTL_A_processed_data.csv`**
- **`TORONTO_NORTH_YORK_processed_data.csv`**

#### **`PCC_matrix.csv`**
Contains the PCC matrix for the 4 climate stations.

---

### **2. `data_processing_script`**
This folder contains Python scripts for processing the downloaded climate data.

#### **`cat.py`**
- Concatenates historical climate data files for a specific station into a single `merged_data.csv`.

#### **`basic_clean.py`**
- Cleans `merged_data.csv` by removing unnecessary columns and creates:
  - `basic_clean_data.csv`: Simplified dataset.
  - `basic_clean_data_report.csv`: Report on the Non-Blank Cell Rate for each column.
- Insights:
  - The **TORONTO_INTL_A** dataset has the highest data completion rate and is prioritized for analysis.
  - Other datasets are secondary options for filling gaps or further analysis.

##### **Columns Removed**
**Not Required for Analysis**:
- *Longitude (x)*
- *Latitude (y)*
- *Climate ID*
- *Date/Time*

**Unrelated to Crime Analysis**:
- *Dir of Max Gust (10s deg)*
- *Dir of Max Gust Flag*
- *Spd of Max Gust (km/h)*
- *Spd of Max Gust Flag*
- *Heat Deg Days (°C)*
- *Heat Deg Days Flag*
- *Cool Deg Days (°C)*
- *Cool Deg Days Flag*

#### **`deep_clean.py`**
- Extracts specified features from `basic_clean_data.csv` and organizes them into `deep_clean_data.csv`.

##### **Selected Features (in order):**
- *Year*
- *Month*
- *Day*
- *Max Temp (°C)*
- *Min Temp (°C)*
- *Mean Temp (°C)*
- *Total Rain (mm)*
- *Total Snow (cm)*
- *Total Precip (mm)*

#### **`processed_data.py`**
- Fills missing values in `deep_clean_data.csv` using linear interpolation and saves as `filled_deep_clean_data.csv`.
- Expands interpolated data across Toronto neighborhoods and outputs the final processed data to the `climate_data` folder.

#### **`compare_pcc.py`**
- Calculates the Pearson Correlation Coefficient (PCC) matrix for Toronto's climate stations.
- Saves the resulting matrix as `PCC_matrix.csv` in the `climate_data` folder.

---
